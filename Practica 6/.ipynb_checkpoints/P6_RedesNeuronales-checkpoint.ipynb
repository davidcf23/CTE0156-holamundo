{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 6: Redes Neuronales (FNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ingeniería Electrónica**\n",
    "\n",
    "**Inteligencia Artificial**\n",
    "\n",
    "**26/06/2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta práctica es proporcionar soluciones a problemas de implementación comunes para las redes neuronales de alimentación directa (FNN) y otras topologías de red.\n",
    "\n",
    "Las FNN son redes en las que la información solo se mueve en una dirección y no hay retroalimentación (a diferencia de las Redes neuronales recurrentes). Las FNN se utilizan principalmente para el aprendizaje supervisado donde los datos no son secuenciales o dependientes del tiempo, por ejemplo, para tareas generales de clasificación y regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El perceptrón\n",
    "\n",
    "Una red neuronal consiste en una o múltiples capas de neuronas, llamadas así por las neuronas biológicas en los cerebros humanos. Vamos a demostrar la mecánica de una sola neurona mediante la implementación de un perceptrón. En un perceptrón, una sola unidad (neurona) realiza todos los cálculos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"perceptron.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la base de datos de Iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, separamos en subconjuntos los datos importados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las dos primeras clases (Iris-Setosa e Iris-Versicolor) son linealmente separables\n",
    "iris = load_iris()\n",
    "idxs = np.where(iris.target<2)\n",
    "X = iris.data[idxs]\n",
    "y = iris.target[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos los datos para dos de las cuatro variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[y==0][:,0],X[y==0][:,2], color='green', label='IrisSetosa')\n",
    "plt.scatter(X[y==1][:,0],X[y==1][:,2], color='red', label='IrisVersicolor')\n",
    "plt.title('Base de datos Iris de plantas')\n",
    "plt.xlabel('longitud del sépalo en cm')\n",
    "plt.ylabel('ancho del sépalo en cm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico anterior, hemos trazado la distribución de las dos clases. Para validar nuestros resultados, dividimos los datos en conjuntos de entrenamiento y validación (o prueba) de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, inicializamos los pesos y bias (sesgo) para el perceptrón:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.normal(size=X_train.shape[1])\n",
    "bias = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrenar, necesitamos definir los hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "n_epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos comenzar a entrenar nuestro perceptrón con un bucle for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_w = np.zeros(weights.shape)\n",
    "hist_loss = []\n",
    "hist_accuracy = []\n",
    "for i in range(n_epochs):\n",
    "    # Aplicamos una función de paso simple (escalón unitario), si la salida es> 0.5 predecimos 1, de lo contrario 0\n",
    "    output = np.where((X_train.dot(weights)+bias)>0.5, 1, 0)\n",
    "    # Calcular MSE\n",
    "    error = np.mean((y_train-output)**2)\n",
    "    # Actualizar pesos y bias\n",
    "    weights-= learning_rate * np.dot((output-y_train), X_train)\n",
    "    bias += learning_rate * np.sum(np.dot((output-y_train), X_train))\n",
    "    # Calcular MSE\n",
    "    loss = np.mean((output - y_train) ** 2)\n",
    "    hist_loss.append(loss)\n",
    "    # Determinar la exactitud de validación\n",
    "    output_val = np.where(X_val.dot(weights)>0.5, 1, 0)\n",
    "    accuracy = np.mean(np.where(y_val==output_val, 1, 0))\n",
    "    hist_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos guardado la pérdida en entrenamiento y la exactitud de validación para poder trazarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "a = fig.add_subplot(1,2,1)\n",
    "imgplot = plt.plot(hist_loss)\n",
    "plt.xlabel('epochs')\n",
    "a.set_title('Pérdida en entrenamiento')\n",
    "a=fig.add_subplot(1,2,2)\n",
    "imgplot = plt.plot(hist_accuracy)\n",
    "plt.xlabel('epochs')\n",
    "a.set_title('Exactitud de validación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de una red neuronal de capa única\n",
    "\n",
    "Ahora podemos pasar a las **redes neuronales**. Comenzaremos implementando la forma más simple de una red neuronal: una red neuronal de capa única. La diferencia con un perceptrón es que los cálculos se realizan por múltiples unidades (neuronas), por lo tanto, una red. \n",
    "\n",
    "Como es de esperar, agregar más unidades aumentará la cantidad de problemas que se pueden resolver. Las unidades realizan sus cálculos por separado y se apilan en una capa; llamamos a esta capa la **capa oculta**. Por lo tanto, llamamos a las unidades apiladas en esta capa las **unidades ocultas** (o neuronas ocultas). Por ahora, solo consideraremos una sola capa oculta. La capa de salida funciona como un perceptrón. Esta vez, como entrada tenemos las unidades ocultas en la capa oculta en lugar de las variables de entrada:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"capa_unica.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestra implementación del perceptrón, hemos utilizado una función de escalón unitario para determinar la clase. En la siguiente implementación, utilizaremos una función de activación no lineal sigmoide para las unidades ocultas y para la función de salida. Al reemplazar la función de paso o escalón con una función de activación no lineal, la red también podrá descubrir patrones no lineales. En el paso hacia atrás, usamos la derivada del sigmoide para actualizar los pesos.\n",
    "\n",
    "En el código siguiente, clasificaremos dos clases no separables linealmente con NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías y conjunto de datos:\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Usaremos make_circles de scikit-learn\n",
    "from sklearn.datasets import make_circles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, necesitamos crear los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un círculo interno y externo\n",
    "X, y = make_circles(n_samples=400, factor=.3, noise=.05, random_state=2020)\n",
    "outer = y == 0\n",
    "inner = y == 1\n",
    "\n",
    "# Normalizamos los datos para asegurarnos de que el centro de ambos círculos es (1,1):\n",
    "X = X+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos los datos para mostrar las dos clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Dos Círculos\")\n",
    "plt.plot(X[outer, 0], X[outer, 1], \"ro\")\n",
    "plt.plot(X[inner, 0], X[inner, 1], \"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar el rendimiento de nuestro algoritmo, dividimos nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una función de activación lineal no funcionará en este caso, por lo que utilizaremos una función sigmoide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, definimos los hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 50 # número de unidades ocultas\n",
    "n_epochs = 1000\n",
    "learning_rate = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos los pesos y otras variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_hidden = np.random.normal(0.0, size=(X_train.shape[1], n_hidden))\n",
    "weights_output = np.random.normal(0.0, size=(n_hidden))\n",
    "hist_loss = []\n",
    "hist_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos la red neuronal de capa única e imprimimos las estadísticas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(n_epochs):\n",
    "    del_w_hidden = np.zeros(weights_hidden.shape)\n",
    "    del_w_output = np.zeros(weights_output.shape)\n",
    "\n",
    "    # Recorrer los datos de entrenamiento en lotes de 1\n",
    "    for x_, y_ in zip(X_train, y_train):\n",
    "        # Cálculos hacia adelante\n",
    "        hidden_input = np.dot(x_, weights_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output = sigmoid(np.dot(hidden_output, weights_output))\n",
    "        # Cálculos hacia atrás\n",
    "        error = y_ - output\n",
    "        output_error = error * output * (1 - output)\n",
    "        hidden_error = np.dot(output_error, weights_output) * hidden_output * (1 - hidden_output)\n",
    "        del_w_output += output_error * hidden_output\n",
    "        del_w_hidden += hidden_error * x_[:, None]\n",
    "        \n",
    "    # Actualizar pesos\n",
    "    weights_hidden += learning_rate * del_w_hidden / X_train.shape[0]\n",
    "    weights_output += learning_rate * del_w_output / X_train.shape[0]\n",
    "    \n",
    "    # Imprimir estadísticas (pérdida y exactitud de validación)\n",
    "    if e % 100 == 0:\n",
    "        hidden_output = sigmoid(np.dot(X_val, weights_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output, weights_output))\n",
    "        loss = np.mean((out - y_val) ** 2)\n",
    "    \n",
    "        # La predicción final se basa en un umbral de 0.5\n",
    "        predictions = out > 0.5\n",
    "        accuracy = np.mean(predictions == y_val)\n",
    "        print(\"Epoch: \", '{:>4}'.format(e), \"; Pérdida de validación: \", '{:>6}'.format(loss.round(4)),\n",
    "              \"; Exactitud de validación: \", '{:>6}'.format(accuracy.round(4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo una red neuronal multicapa\n",
    "\n",
    "Lo que hemos creado en código anterior es en realidad la forma más simple de una FNN: una red neuronal donde la información fluye solo en una dirección. Para nuestra próxima receta, ampliaremos el número de capas ocultas de una a varias capas. Agregar capas adicionales aumenta el poder de una red para aprender patrones no lineales complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"multicapa.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al agregar una capa adicional, el número de conexiones (pesos), también llamados parámetros entrenables, aumenta exponencialmente. En la siguiente implemetación, crearemos una red con dos capas ocultas para predecir la **calidad de vino** con datos de vinos tintos descargado de https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/. Sin embargo, el archivo CSV ya se incluye en la carpeta de la práctica. \n",
    "\n",
    "Esta es una **tarea de regresión**, por lo que utilizaremos una activación lineal para la capa de salida. Para las capas ocultas, utilizamos las funciones de activación de **ReLU**. Esta receta utiliza el framework de **Keras** para implementar la FNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pip install tensorflow==2.1\n",
    "# pip install Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep=';')\n",
    "y = data['quality']\n",
    "X = data.drop(['quality'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar datos para entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos la calidad promedio y las primeras filas del conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calidad promedio del conjunto de entrenamiento: {:.4f}'.format(y_train.mean()))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso importante es normalizar los datos de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, construyamos nuestra red neuronal definiendo la arquitectura de red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Primera capa oculta con 200 unidades ocultas\n",
    "model.add(Dense(200, input_dim=X_train.shape[1],\n",
    "activation='relu'))\n",
    "# Segunda capa oculta con 25 unidades ocultas\n",
    "model.add(Dense(25, activation='relu'))\n",
    "# Capa de salida\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# Establecer optimizador\n",
    "opt = Adam()\n",
    "# Compilar modelo\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos la retrollamada para detener y guardar el mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "EarlyStopping(monitor='val_accuracy', patience=20, verbose=2),\n",
    "ModelCheckpoint('checkpoints/multi_capa_mejor_modelo.h5',\n",
    "monitor='val_accuracy', save_best_only=True, verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos el modelo con un tamaño de lote de 64, 5000 épocas y una división de validación del 20%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 5000\n",
    "model.fit(X_train.values, y_train, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, verbose=2,\n",
    "callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos imprimir el rendimiento en el conjunto de prueba después de cargar los pesos óptimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model\n",
    "best_model.load_weights('checkpoints/multi_capa_mejor_modelo.h5')\n",
    "best_model.compile(loss='mse', optimizer='adam' ,metrics=['accuracy'])\n",
    "# Evaluar en conjunto de prueba\n",
    "score_test = best_model.evaluate(X_test.values, y_test, verbose=0)\n",
    "score_train = best_model.evaluate(X_train.values, y_train, verbose=0)\n",
    "print('Exactitud en prueba: %.2f%%' % (score_test[1]*100))\n",
    "print('Exactitud en entrenamiento: %.2f%%' % (score_train[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando funciones de activación\n",
    "\n",
    "Si solo utilizamos funciones de activación lineal, una red neuronal representaría una gran colección de combinaciones lineales. Sin embargo, el poder de las redes neuronales radica en su capacidad para modelar comportamientos no lineales complejos. Introdujimos brevemente las funciones de activación no lineal sigmoide y ReLU en las implementaciones anteriores, y hay muchas funciones de activación no lineales más populares, como **ELU**, **Leaky ReLU**, **TanH** y **Maxout**. \n",
    "\n",
    "No existe una regla general sobre qué activación funciona mejor para las unidades ocultas. Deep Learning o es un campo en investigacion y la mayoría de los resultados se obtienen por prueba y error en lugar de pruebas matemáticas.\n",
    "\n",
    "En la siguiente implementación, compararemos la diferencia en los resultados entre una función de activación sigmoide y ReLU al clasificar los dígitos escritos a mano con una FNN profunda. El conjunto de datos se extrae desde Keras y corresponde a la base de datos MNIST (*Modified National Institute of Standards and Technology database*) de dígitos escritos a mano, accesible también en: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías y conjunto de datos:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el conjunto de datos MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar un ejemplo de cada etiqueta e imprimir el conteo por etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la primera imagen de cada etiqueta\n",
    "unique_labels = set(y_train)\n",
    "plt.figure(figsize=(12, 12))\n",
    "i = 1\n",
    "for label in unique_labels:\n",
    "    image = X_train[y_train.tolist().index(label)]\n",
    "    plt.subplot(10, 10, i)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"{0}: ({1})\".format(label,\n",
    "    y_train.tolist().count(label)))\n",
    "    i += 1\n",
    "    _ = plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar datos\n",
    "X_train = X_train.astype('float32')/255.\n",
    "X_val = X_val.astype('float32')/255.\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "# Acoplar datos: tratamos la imagen como una matriz secuencial de valores\n",
    "X_train = np.reshape(X_train, (60000, 784))\n",
    "X_val = np.reshape(X_val, (10000, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir el modelo con la función de activación **sigmoide**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Dense(700, input_dim=784, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(700, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(700, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(700, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(700, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(350, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(100, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilar modelo con SGD\n",
    "model_sigmoid.compile(loss='categorical_crossentropy',\n",
    "optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir el modelo con la función de activación **ReLU**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(700, input_dim=784, activation='relu'))\n",
    "model_relu.add(Dense(700, activation='relu'))\n",
    "model_relu.add(Dense(700, activation='relu'))\n",
    "model_relu.add(Dense(700, activation='relu'))\n",
    "model_relu.add(Dense(700, activation='relu'))\n",
    "model_relu.add(Dense(350, activation='relu'))\n",
    "model_relu.add(Dense(100, activation='relu'))\n",
    "model_relu.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilar modelo con SGD\n",
    "model_relu.compile(loss='categorical_crossentropy',\n",
    "optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear una función de retrollamada para almacenar los valores de pérdida por lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class history_loss(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        batch_loss = logs.get('loss')\n",
    "        self.losses.append(batch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 256\n",
    "validation_split = 0.2\n",
    "\n",
    "history_sigmoid = history_loss()\n",
    "model_sigmoid.fit(X_train, y_train,\n",
    "                  epochs=n_epochs, batch_size=batch_size,\n",
    "                  callbacks=[history_sigmoid], validation_split=validation_split, verbose=2)\n",
    "\n",
    "history_relu = history_loss()\n",
    "model_relu.fit(X_train, y_train,\n",
    "               epochs=n_epochs, batch_size=batch_size, \n",
    "               callbacks=[history_relu], validation_split=validation_split, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficar pérdidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(history_sigmoid.losses)), history_sigmoid.losses, label='sigmoid')\n",
    "plt.plot(np.arange(len(history_relu.losses)), history_relu.losses, label='relu')\n",
    "plt.title('Pérdidas')\n",
    "plt.xlabel('Número de lotes')\n",
    "plt.ylabel('pérdida')\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer los pesos máximos de cada modelo por capa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sigmoid = []\n",
    "w_relu = []\n",
    "for i in range(len(model_sigmoid.layers)):\n",
    "    w_sigmoid.append(max(model_sigmoid.layers[i].get_weights()[1]))\n",
    "    w_relu.append(max(model_relu.layers[i].get_weights()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficar los pesos de ambos modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(len(model_sigmoid.layers))\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar(index, w_sigmoid, bar_width, label='sigmoid',\n",
    "color='b', alpha=0.4)\n",
    "plt.bar(index + bar_width, w_relu, bar_width, label='relu',\n",
    "color='r', alpha=0.4)\n",
    "plt.title('Pesos a través de la capas')\n",
    "plt.xlabel('Número de capa')\n",
    "plt.ylabel('peso máximo')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.xticks(index + bar_width / 2, np.arange(8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las redes neuronales convolucionales, revisaremos cómo obtener más del 99% de exactitud en el conjunto de datos MNIST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
